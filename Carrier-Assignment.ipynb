{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"zeta-disease_training-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>bmi</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>insulin_test</th>\n",
       "      <th>liver_stress_test</th>\n",
       "      <th>cardio_stress_test</th>\n",
       "      <th>years_smoking</th>\n",
       "      <th>zeta_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>189</td>\n",
       "      <td>27.1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5038</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>150</td>\n",
       "      <td>38.5</td>\n",
       "      <td>68</td>\n",
       "      <td>71</td>\n",
       "      <td>0.3868</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>186</td>\n",
       "      <td>29.9</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2728</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>150</td>\n",
       "      <td>30.8</td>\n",
       "      <td>70</td>\n",
       "      <td>1033</td>\n",
       "      <td>0.6598</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>160</td>\n",
       "      <td>32.4</td>\n",
       "      <td>74</td>\n",
       "      <td>125</td>\n",
       "      <td>0.7608</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  weight   bmi  blood_pressure  insulin_test  liver_stress_test  \\\n",
       "0   54     189  27.1              80             0             1.5038   \n",
       "1   23     150  38.5              68            71             0.3868   \n",
       "2   47     186  29.9              90             0             0.2728   \n",
       "3   18     150  30.8              70          1033             0.6598   \n",
       "4   24     160  32.4              74           125             0.7608   \n",
       "\n",
       "   cardio_stress_test  years_smoking  zeta_disease  \n",
       "0                   0             10             0  \n",
       "1                  55              2             0  \n",
       "2                   0              7             0  \n",
       "3                  56              0             0  \n",
       "4                  59              2             0  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>bmi</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>insulin_test</th>\n",
       "      <th>liver_stress_test</th>\n",
       "      <th>cardio_stress_test</th>\n",
       "      <th>years_smoking</th>\n",
       "      <th>zeta_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30.985000</td>\n",
       "      <td>172.407500</td>\n",
       "      <td>32.201625</td>\n",
       "      <td>69.565000</td>\n",
       "      <td>85.887500</td>\n",
       "      <td>0.544496</td>\n",
       "      <td>43.121250</td>\n",
       "      <td>4.051250</td>\n",
       "      <td>0.348750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.824025</td>\n",
       "      <td>31.942438</td>\n",
       "      <td>8.549155</td>\n",
       "      <td>19.874784</td>\n",
       "      <td>126.333656</td>\n",
       "      <td>0.348711</td>\n",
       "      <td>30.409949</td>\n",
       "      <td>4.176173</td>\n",
       "      <td>0.476873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>32.050000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.445300</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>36.525000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>0.699800</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>109.000000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>86.100000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>1077.000000</td>\n",
       "      <td>3.481300</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age      weight         bmi  blood_pressure  insulin_test  \\\n",
       "count  800.000000  800.000000  800.000000      800.000000    800.000000   \n",
       "mean    30.985000  172.407500   32.201625       69.565000     85.887500   \n",
       "std     13.824025   31.942438    8.549155       19.874784    126.333656   \n",
       "min     18.000000   94.000000    0.000000        0.000000      0.000000   \n",
       "25%     21.000000  149.000000   27.300000       62.000000      0.000000   \n",
       "50%     26.000000  167.000000   32.050000       72.000000     45.000000   \n",
       "75%     38.000000  192.000000   36.525000       80.000000    130.000000   \n",
       "max    109.000000  308.000000   86.100000      157.000000   1077.000000   \n",
       "\n",
       "       liver_stress_test  cardio_stress_test  years_smoking  zeta_disease  \n",
       "count         800.000000          800.000000     800.000000    800.000000  \n",
       "mean            0.544496           43.121250       4.051250      0.348750  \n",
       "std             0.348711           30.409949       4.176173      0.476873  \n",
       "min             0.140800            0.000000       0.000000      0.000000  \n",
       "25%             0.307800            0.000000       1.000000      0.000000  \n",
       "50%             0.445300           53.000000       3.000000      0.000000  \n",
       "75%             0.699800           62.000000       6.000000      1.000000  \n",
       "max             3.481300          214.000000      40.000000      1.000000  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                     int64\n",
       "weight                  int64\n",
       "bmi                   float64\n",
       "blood_pressure          int64\n",
       "insulin_test            int64\n",
       "liver_stress_test     float64\n",
       "cardio_stress_test      int64\n",
       "years_smoking           int64\n",
       "zeta_disease            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's inspect the type of variables in pandas\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    521\n",
       "1    279\n",
       "Name: zeta_disease, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspecting the data\n",
    "df['zeta_disease'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### observation: It is an imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2289688e828>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x792 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corrmat = df.corr()\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(11,11)\n",
    "sns.heatmap(corrmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking for Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                   0\n",
       "weight                0\n",
       "bmi                   0\n",
       "blood_pressure        0\n",
       "insulin_test          0\n",
       "liver_stress_test     0\n",
       "cardio_stress_test    0\n",
       "years_smoking         0\n",
       "zeta_disease          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Outlier engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD7CAYAAAB5aaOHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWQklEQVR4nO3df5Bd5X3f8fdHu4DBGFssgmIJAh5R2zjEdthSu8YtU4ugOJGgnZKQqaOt4ymtSwR1GreQusV2hxk7Q9sEGjtRbcdL/IPBjidIDVUiKTUxM46pCEwwYAaNMSDAQl4agw3GXunbP/YIX8kr6VyhvWev9v2aOXPuee5z7/kus9oPz/nxnFQVkiQdzKKuC5AkDQcDQ5LUioEhSWrFwJAktWJgSJJaMTAkSa0YGNI8lKSSLO+6DqmXgSEdRJJvJXk+yfeS/L8kf5rktK7rAkjyL5Lc0XUdWhgMDKmdVVV1PHAqsAO4seN6pIEzMKQ+VNUPgC8CZwMkeWWSm5LsTPJIkg8kWZTkxCTbk6xq+h2fZFuSNc32p5P8fpJNSZ5NcnuSn5ptnwfYx+uB3wfe2ox+/nYw/xW0UBkYUh+SHAf8MvBXTdONwCuB1wD/CFgDvLuqngZ+DfifSU4G/jtwT1Xd1PN1/xz4L8BJwD3AZ/ez2/3t4wHgXwNfrarjq+pVh+0HlWYx2nUB0pD4kyTTwPHAU8BFSUaYCY83V9WzwLNJ/ivwq8Anq+rPk3wB2AKMAefs851/WlV/CZDkPwLfTXJaVT22p8PB9jGXP7C0L0cYUjuXNP8Hfwzw68DtwDLgaOCRnn6PAEt7ttcBPw38YVVN7fOdLwZDVX0PeBp49T59TmqxD2kgDAypD1W1q6q+BOwC3gL8COg993A68Di8ODr4A+Am4L2zXCb74pVWSY4HTgSe2KfPdw60D8DppjUwBobUh8y4GFgMfB24BbguySuak9a/AXym6f5bzfrXgOuBm5oQ2eOdSc5PcjQz5zK+1ns4CmYC6iD72AEsa75DmlMGhtTOhiTfA54BrgMmquo+YC3wfeCbwB3A54BPJTmXmT/sa5o/+h9lZjRwdc93fg64lplDUecycxJ8NrPuo3nvL4D7gG8n+c7h+VGl2cUHKEmDl+TTwPaq+kDXtUhtOcKQJLViYEiSWvGQlCSpFUcYkqRWDAxJUitH9NQgJ510Up1xxhldlyFJQ+Ouu+76TlUtme29IzowzjjjDLZu3dp1GZI0NJI8sr/3PCQlSWrFwJAktWJgSJJaMTAkSa0YGNKATU1NceWVVzI1te/jMaT5zcCQBmxycpJ7772Xm2666eCdpXnEwJAGaGpqio0bN1JVbNy40VGGhoqBIQ3Q5OQku3fvBmDXrl2OMjRUDAxpgDZv3sz09DQA09PTbNq0qeOKpPYMDGmAVqxYwejozAQLo6OjXHjhhR1XJLVnYEgDNDExwaJFM//sRkZGWLNmTccVSe0ZGNIAjY2NsXLlSpKwcuVKxsbGui5Jas3AkAZs9erVHHfccaxatarrUqS+GBjSgK1fv57nnnuODRs2dF2K1BcDQxog78PQMDMwpAHyPgwNMwNDGiDvw9AwMzCkAfI+DA2zOQ2MJJ9K8lSSr/e0nZhkU5KHmvXinveuSbItyYNJLuppPzfJvc17NyTJXNYtzRXvw9Awm+sRxqeBlfu0XQ1sqaqzgC3NNknOBi4D3tB85mNJRprPfBy4HDirWfb9TmkoeB+GhtmcBkZV/SXw9D7NFwOTzetJ4JKe9pur6oWqehjYBpyX5FTghKr6alUVcFPPZ6ShMzExwTnnnOPoQkNntIN9nlJVTwJU1ZNJTm7alwJ/1dNve9P2o+b1vu3SUBobG+OGG27ougypb/PppPds5yXqAO2zf0lyeZKtSbbu3LnzsBUnSQtdF4GxoznMRLN+qmnfDpzW028Z8ETTvmyW9llV1bqqGq+q8SVLlhzWwiVpIesiMNYDE83rCeDWnvbLkhyT5ExmTm7f2Ry+ejbJW5qro9b0fEaSNCBzeg4jyeeBC4CTkmwHrgU+AtyS5D3Ao8ClAFV1X5JbgPuBaeCKqtrVfNV7mbni6ljgfzeLJGmAMnPh0ZFpfHy8tm7d2nUZkjQ0ktxVVeOzvTefTnpLkuYxA0OS1IqBIUlqxcCQJLViYEiSWjEwJEmtGBiSpFYMDElSKwaGJKkVA0OS1IqBIUlqxcCQJLViYEiSWjEwJEmtGBiSpFYMDElSKwaGJKkVA0OS1IqBIUlqxcCQBmxqaoorr7ySqamprkuR+mJgSAM2OTnJvffey0033dR1KVJfDAxpgKampti4cSNVxcaNGx1laKgYGNIATU5Osnv3bgB27drlKENDxcCQBmjz5s1MT08DMD09zaZNmzquSGrPwJAGaMWKFYyOjgIwOjrKhRde2HFFUnsGhjRAExMTLFo0889uZGSENWvWdFyR1J6BIQ3Q2NgYK1euJAkrV65kbGys65Kk1ka7LkBaaCYmJvjWt77l6EJDp7MRRpL3JbkvydeTfD7Jy5KcmGRTkoea9eKe/tck2ZbkwSQXdVW39FKNjY1xww03OLrQ0OkkMJIsBa4Exqvqp4ER4DLgamBLVZ0FbGm2SXJ28/4bgJXAx5KMdFG7JC1UXZ7DGAWOTTIKHAc8AVwMTDbvTwKXNK8vBm6uqheq6mFgG3DegOuVpAWtk8CoqseB64FHgSeB71bVnwOnVNWTTZ8ngZObjywFHuv5iu1NmyRpQLo6JLWYmVHDmcCrgZcnedeBPjJLW+3nuy9PsjXJ1p07d770YiVJQHeHpFYAD1fVzqr6EfAl4B8AO5KcCtCsn2r6bwdO6/n8MmYOYf2EqlpXVeNVNb5kyZI5+wEkaaHpKjAeBd6S5LgkAd4BPACsByaaPhPArc3r9cBlSY5JciZwFnDngGuWpAWtk/swquprSb4I/DUwDdwNrAOOB25J8h5mQuXSpv99SW4B7m/6X1FVu7qoXZIWqlTNeirgiDA+Pl5bt27tugxJGhpJ7qqq8dnec2oQSVIrBoY0YD6iVcPKwJAGzEe0algZGNIA+YhWDTMDQxogH9GqYWZgSAPkI1o1zAwMaYB8RKuGmYEhDZCPaNUwMzCkAfIRrRpmPqJVGjAf0aphZWBIA7bnEa3SsPGQlCSpFQNDktSKgSENmHNJaVgZGNKAOZeUhpWBIQ2Qc0lpmLUOjCRb2rRJ2j/nktIwO2hgJHlZkhOBk5IsTnJis5wBvHquC5SOJM4lpWHWZoTxr4C7gNc16z3LrcDvzV1p0pHHuaQ0zA4aGFX1u1V1JvCbVfWaqjqzWd5YVf9jADVKRwznktIw6+ek97eTvAIgyQeSfCnJz85RXdIRybmkNMz6CYz/VFXPJjkfuAiYBD4+N2VJR66JiQnOOeccRxcaOv0Exq5m/QvAx6vqVuDow1+SdGTbM5eUowsNm34C4/EkfwD8EnBbkmP6/LwkaYj18wf/l4A/A1ZW1d8CJwLvn5OqJEnzTuvAqKrngKeA85umaeChuShKkjT/9HOn97XAfwCuaZqOAj4zF0VJkuaffg5J/RNgNfB9gKp6AnjFXBQlHcmcrVbDqp/A+GFVFVAASV7+Unac5FVJvpjkG0keSPLWZsqRTUkeataLe/pfk2RbkgeTXPRS9i11ydlqNaz6CYxbmqukXpXkXwKbgU+8hH3/LrCxql4HvBF4ALga2FJVZwFbmm2SnA1cBrwBWAl8LMnIS9i31Alnq9Uw6+ek9/XAF4E/Bl4L/OeqOqQHEyc5AfiHwCeb7/5hc+XVxczcEEizvqR5fTFwc1W9UFUPA9uA8w5l31KXnK1Ww6yfk94frapNVfX+qvrNqtqU5KOHuN/XADuBP0xyd5JPNIe4TqmqJwGa9clN/6XAYz2f3960zVbn5Um2Jtm6c+fOQyxPmhvOVqth1s8hqdmm1fz5Q9zvKPCzzNwx/mZmTqRffYD+maWtZutYVeuqaryqxpcsWXKI5UlzY8WKFSQzv85JnK1WQ6XN8zDem+Re4LVJ/qZneRj4m0Pc73Zge1V9rdn+IjMBsiPJqc1+T2Xmvo89/U/r+fwy4IlD3LfUmdWrVzNz7QhUFatWreq4Iqm9NiOMzwGrgPXNes9yblW9a0+n3iuaDqaqvg08luS1TdM7gPubfUw0bRPMPHODpv2yJMckORM4C7iz7f6k+WL9+vV7jTA2bNjQcUVSe6MH61BV3wW+C/zKQbpuYWaU0NZa4LNJjga+CbybmQC7Jcl7gEeBS5sa7ktyCzOhMg1cUVW7Zv9aaf7avHnzXiOMTZs28b73va/jqqR2DhoYfZjtPMN+VdU9wPgsb71jP/2vA647hLqkeWPFihXcdtttTE9P+8Q9DZ3DOdvsrCehJf1Y7xP3Fi1a5DMxNFScnlwaoLGxMRYvnjndt3jxYp+JoaFyOAOjr0NS0kI0NTXFjh07ANixY4d3emuo9BUYSUaSvDrJ6XuWnrdnPfcg6ceuv/76A25L81nrk95J1gLXAjuA3U1zAT8DUFVPH/bqpCPMV7/61QNuS/NZP1dJXQW8tqocQ0vSAtTPIanHmLkfQ9IhevnLX37AbWk+6ycwvgl8uXkuxW/sWeaqMOlI9KEPfWiv7Q9/+MMdVSL1r59DUo82y9HNIqlP4+PjjI6Ovnjj3rnnntt1SVJrrQOjqj508F6SDqT3MtokTE1NeS+Ghkab2Wp/p1lvSLJ+32XuS5SOHJOTky/OJbV7924foKSh0maE8UfN2gvGpZdo8+bN7No1M2/mrl27nHxQQ6XNbLV3Nevb574c6cj2xje+ca97L970pjd1WI3Un4MGRvPwpP1OLFhVP3NYK5KOYPfcc89e23fffXdHlUj9a3NI6hfnvAppgXj++ecPuC3NZ20OST0yiEIkSfNbP3NJPcuPD00dDRwFfL+qTpiLwiRJ80s/92G8onc7ySXAeYe9IknSvHTIz8Ooqj8B/vFhrEU64o2MjBxwW5rP+jkk9U97Nhcx8zxuH8sq9WF0dPTF+zD2bEvDop8Rxqqe5SLgWeDiuShKOlJddNFFe22vXLmyo0qk/vVzDuPdc1mItBBMTEywfv2PZ9RZs2ZNh9VI/Wk9wkjy20lOSHJUki1JvpPkXXNZnHQkWrRo0V5raVj08xv7c1X1DDM38m0H/i7w/jmpSjpCTU5OkgSYma3WyQc1TPoJjKOa9TuBz/sMb6l/s00+KA2LfgJjQ5JvMHN11JYkS4AfzE1Z0pFpxYoVe40wLrzwwo4rktprHRhVdTXwVmC8qn4EfB+vkpL6snr16hefh1FVrFq1quOKpPb6Pev2euCXk6wB/hnwcy9l50lGktyd5H812ycm2ZTkoWa9uKfvNUm2JXkwyUX7/1Zp/lq/fv1eI4wNGzZ0XJHUXj9XSf0RMw9ROh/4e80y/hL3fxXwQM/21cCWqjoL2NJsk+Rs4DLgDcBK4GNJvEVWQ2fz5s17jTA8h6Fh0s8IYxx4W1X9m6pa2yxXHuqOkywDfgH4RE/zxcBk83oSuKSn/eaqeqGqHga24TxWGkJvf/vbD7gtzWf9BMbXgb9zGPf9O8C/B3b3tJ1SVU8CNOuTm/alwGM9/bY3bdJQ+cEP9r5O5IUXXuioEql//UxkcxJwf5I7gRd/y6tqdb87TfKLwFNVdVeSC9p8ZJa2WeexSnI5cDnA6aef3m9p0py644479tr+yle+0lElUv/6CYwPHsb9vg1YneSdwMuAE5J8BtiR5NSqejLJqcBTTf/twGk9n18GPDHbF1fVOmAdwPj4uJMjal7ZvXv3Abel+ayfy2pvn205lJ1W1TVVtayqzmDmZPZfVNW7gPXARNNtAri1eb0euCzJMUnOBM4C7jyUfUtd2nc6EKcH0TA56G9rkjua9bNJnulZnk3yzGGu5yPAhUkeAi5stqmq+4BbgPuBjcAVVbVrv98izVPnn3/+Xtue9NYwafNM7/Ob9SsO1vdQVNWXgS83r6eAd+yn33XAdXNRgzQoe+7BkIaR42FpgPY9ye1Jbw0TA0MaoN6n7c22Lc1nBoY0QD7TW8PMwJAGaMWKFQfcluYzA0MaoEsvvfSA29J8ZmBIA/SFL3zhgNvSfGZgSAO07+y0zlarYWJgSAPk1CAaZv3MJSUdshtvvJFt27Z1Xca8dNVVV3VdQqeWL1/O2rVruy5DLTjCkCS14ghDA+H/Qc649tpruf32H8/ZecEFF/DBD36wu4KkPjjCkAboyiv3fkilQaphYmBIAzQ2NsYrX/lKYGZ0MTY21nFFUnsekpIGbOnSpUxPTzu60NBxhCEN2FFHHcXy5csdXWjoGBiSpFYMDElSKwaGJKkVA0OS1IqBIUlqxcCQJLViYEiSWjEwJEmtGBiSpFYMDElSKwaGJKkVA0OS1IqBIUlqpZPASHJakv+T5IEk9yW5qmk/McmmJA8168U9n7kmybYkDya5qIu6JWkh62qEMQ38u6p6PfAW4IokZwNXA1uq6ixgS7NN895lwBuAlcDHkox0UrkkLVCdBEZVPVlVf928fhZ4AFgKXAxMNt0mgUua1xcDN1fVC1X1MLANOG+wVUvSwtb5OYwkZwBvBr4GnFJVT8JMqAAnN92WAo/1fGx70yZJGpBOAyPJ8cAfA/+2qp45UNdZ2mo/33l5kq1Jtu7cufNwlClJosPASHIUM2Hx2ar6UtO8I8mpzfunAk817duB03o+vgx4Yrbvrap1VTVeVeNLliyZm+IlaQHq6iqpAJ8EHqiq/9bz1npgonk9Adza035ZkmOSnAmcBdw5qHolSTDa0X7fBvwqcG+Se5q23wI+AtyS5D3Ao8ClAFV1X5JbgPuZucLqiqraNfiyJWnh6iQwquoOZj8vAfCO/XzmOuC6OStKknRAnV8lJUkaDgaGJKkVA0OS1IqBIUlqxcCQJLViYEiSWjEwJEmtdHXj3oJw4403sm3btq7L0Dyz53fiqquu6rgSzTfLly9n7dq1XZexXwbGHNq2bRv3fP0Bdh13YtelaB5Z9MOZeTPv+uaOjivRfDLy3NNdl3BQBsYc23XciTz/und2XYakee7Yb9zWdQkH5TkMSVIrBoYkqRUDQ5LUioEhSWrFwJAktWJgSJJaMTAkSa0YGJKkVgwMSVIrBoYkqRUDQ5LUioEhSWrFyQfn0OOPP87Ic98diknFJHVr5LkpHn98uusyDsgRhiSpFUcYc2jp0qV8+4VRpzeXdFDHfuM2li49pesyDsgRhiSpFQNDktSKgSFJamWoAiPJyiQPJtmW5Oqu65GkhWRoAiPJCPB7wM8DZwO/kuTsbquSpIVjmK6SOg/YVlXfBEhyM3AxcH+nVR3EyHNPex8GsOgHz5DdP+q6DM1Dtegodr/shK7L6NzIc08D8/sqqWEKjKXAYz3b24G/v2+nJJcDlwOcfvrpg6lsP5YvX97p/ueTxx+f5vnnn++6DM1Dxx577Ly/nHQwTpn3fzOGKTAyS1v9REPVOmAdwPj4+E+8P0hr167tcveSdFgNzTkMZkYUp/VsLwOe6KgWSVpwhikw/i9wVpIzkxwNXAas77gmSVowhuaQVFVNJ/l14M+AEeBTVXVfx2VJ0oIxNIEBUFW3AV5yJEkdGKZDUpKkDhkYkqRWDAxJUisGhiSplVR1em/bnEqyE3ik6zqkWZwEfKfrIqRZ/FRVLZntjSM6MKT5KsnWqhrvug6pHx6SkiS1YmBIkloxMKRurOu6AKlfnsOQJLXiCEOS1IqBIUlqxcCQJLViYEiSWjEwJEmt/H/5PcnlklTr3QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    sns.boxplot(y=df[col])\n",
    "    plt.title('Boxplot')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_skewed_boundaries(df, variable, distance):\n",
    "\n",
    "    # Let's calculate the boundaries outside which sit the outliers\n",
    "    # for skewed distributions\n",
    "\n",
    "    IQR = df[variable].quantile(0.75) - df[variable].quantile(0.25)\n",
    "\n",
    "    lower_boundary = df[variable].quantile(0.25) - (IQR * distance)\n",
    "    upper_boundary = df[variable].quantile(0.75) + (IQR * distance)\n",
    "\n",
    "    return upper_boundary, lower_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_boundaries(df, variable):\n",
    "\n",
    "    # the boundaries are the quantiles\n",
    "\n",
    "    lower_boundary = df[variable].quantile(0.05)\n",
    "    upper_boundary = df[variable].quantile(0.95)\n",
    "\n",
    "    return upper_boundary, lower_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256.5, 84.5)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_upper_limit, weight_lower_limit = find_skewed_boundaries(df, 'weight', 1.5)\n",
    "weight_upper_limit, weight_lower_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233.0, 130.0)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_g_upper_limit, weight_g_lower_limit = find_boundaries(df, 'weight')\n",
    "weight_g_upper_limit, weight_g_lower_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50.3625, 13.462500000000004)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmi_upper_limit, bmi_lower_limit = find_skewed_boundaries(df, 'bmi', 1.5)\n",
    "bmi_upper_limit, bmi_lower_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44.61999999999998, 21.8)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmi_g_upper_limit, bmi_g_lower_limit = find_boundaries(df, 'bmi')\n",
    "bmi_g_upper_limit, bmi_g_lower_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bmi']= np.where(df['bmi'] > bmi_upper_limit, bmi_upper_limit,\n",
    "                       np.where(df['bmi'] < bmi_lower_limit, bmi_lower_limit, df['bmi']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107.0, 35.0)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blood_pressure_upper_limit, blood_pressure_lower_limit = find_skewed_boundaries(df, 'blood_pressure', 1.5)\n",
    "blood_pressure_upper_limit, blood_pressure_lower_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92.0, 43.80000000000001)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blood_pressure_g_upper_limit, blood_pressure_g_lower_limit = find_boundaries(df, 'blood_pressure')\n",
    "blood_pressure_g_upper_limit, blood_pressure_g_lower_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['blood_pressure']= np.where(df['blood_pressure'] > bmi_upper_limit, bmi_upper_limit,\n",
    "                       np.where(df['blood_pressure'] < bmi_lower_limit, bmi_lower_limit, df['blood_pressure']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(325.0, -195.0)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insulin_test_upper_limit, insulin_test_lower_limit = find_skewed_boundaries(df, 'insulin_test', 1.5)\n",
    "insulin_test_upper_limit, insulin_test_lower_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310.39999999999964, 0.0)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insulin_test_g_upper_limit, insulin_test_g_lower_limit = find_boundaries(df, 'insulin_test')\n",
    "insulin_test_g_upper_limit, insulin_test_g_lower_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['insulin_test']= np.where(df['insulin_test'] > insulin_test_upper_limit, insulin_test_upper_limit,\n",
    "                       np.where(df['insulin_test'] < insulin_test_lower_limit, insulin_test_lower_limit, df['insulin_test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.2877999999999998, -0.28019999999999995)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liver_stress_test_upper_limit, liver_stress_test_lower_limit = find_skewed_boundaries(df, 'liver_stress_test', 1.5)\n",
    "liver_stress_test_upper_limit, liver_stress_test_lower_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['liver_stress_test']= np.where(df['liver_stress_test'] > liver_stress_test_upper_limit, liver_stress_test_upper_limit,\n",
    "                       np.where(df['liver_stress_test'] < liver_stress_test_lower_limit, liver_stress_test_lower_limit, df['liver_stress_test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>bmi</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>insulin_test</th>\n",
       "      <th>liver_stress_test</th>\n",
       "      <th>cardio_stress_test</th>\n",
       "      <th>years_smoking</th>\n",
       "      <th>zeta_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30.985000</td>\n",
       "      <td>172.407500</td>\n",
       "      <td>32.171422</td>\n",
       "      <td>48.575438</td>\n",
       "      <td>77.772500</td>\n",
       "      <td>0.529669</td>\n",
       "      <td>43.121250</td>\n",
       "      <td>4.051250</td>\n",
       "      <td>0.348750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.824025</td>\n",
       "      <td>31.942438</td>\n",
       "      <td>7.088368</td>\n",
       "      <td>7.678616</td>\n",
       "      <td>95.586658</td>\n",
       "      <td>0.291608</td>\n",
       "      <td>30.409949</td>\n",
       "      <td>4.176173</td>\n",
       "      <td>0.476873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>13.462500</td>\n",
       "      <td>13.462500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>50.362500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>32.050000</td>\n",
       "      <td>50.362500</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.445300</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>36.525000</td>\n",
       "      <td>50.362500</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>0.699800</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>109.000000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>50.362500</td>\n",
       "      <td>50.362500</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>1.287800</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age      weight         bmi  blood_pressure  insulin_test  \\\n",
       "count  800.000000  800.000000  800.000000      800.000000    800.000000   \n",
       "mean    30.985000  172.407500   32.171422       48.575438     77.772500   \n",
       "std     13.824025   31.942438    7.088368        7.678616     95.586658   \n",
       "min     18.000000   94.000000   13.462500       13.462500      0.000000   \n",
       "25%     21.000000  149.000000   27.300000       50.362500      0.000000   \n",
       "50%     26.000000  167.000000   32.050000       50.362500     45.000000   \n",
       "75%     38.000000  192.000000   36.525000       50.362500    130.000000   \n",
       "max    109.000000  308.000000   50.362500       50.362500    325.000000   \n",
       "\n",
       "       liver_stress_test  cardio_stress_test  years_smoking  zeta_disease  \n",
       "count         800.000000          800.000000     800.000000    800.000000  \n",
       "mean            0.529669           43.121250       4.051250      0.348750  \n",
       "std             0.291608           30.409949       4.176173      0.476873  \n",
       "min             0.140800            0.000000       0.000000      0.000000  \n",
       "25%             0.307800            0.000000       1.000000      0.000000  \n",
       "50%             0.445300           53.000000       3.000000      0.000000  \n",
       "75%             0.699800           62.000000       6.000000      1.000000  \n",
       "max             1.287800          214.000000      40.000000      1.000000  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature Selection Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [feature1, feature2, corr]\n",
       "Index: []"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_values=df.drop(labels=['zeta_disease'],axis=1)\n",
    "corrmat = df_x_values.corr()\n",
    "corrmat = corrmat.abs().unstack() \n",
    "corrmat = corrmat.sort_values(ascending=False)\n",
    "corrmat = corrmat[corrmat >= 0.6]\n",
    "corrmat = corrmat[corrmat < 1]\n",
    "corrmat = pd.DataFrame(corrmat).reset_index()\n",
    "corrmat.columns = ['feature1', 'feature2', 'corr']\n",
    "corrmat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(df_x_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "        norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel= SelectFromModel(LogisticRegression(C=1, penalty='l1'))\n",
    "sel.fit(scaler.transform(df_x_values.fillna(0)), df['zeta_disease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 8\n",
      "selected features: 8\n",
      "features with coefficients shrank to zero: 0\n"
     ]
    }
   ],
   "source": [
    "# Now I make a list with the selected features\n",
    "selected_feat = df_x_values.columns[(sel.get_support())]\n",
    "\n",
    "print('total features: {}'.format((df_x_values.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat)))\n",
    "print('features with coefficients shrank to zero: {}'.format(\n",
    "    np.sum(sel.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 8), (800,))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and validation\n",
    "X_train, y_train=df.drop(labels=['zeta_disease'],axis=1), df['zeta_disease']\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5355086372360844"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_train)\n",
    "279/521"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_scale = sc.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] C=1.49816047538945, penalty=l2 ..................................\n",
      "[CV] ................... C=1.49816047538945, penalty=l2, total=   0.0s\n",
      "[CV] C=1.49816047538945, penalty=l2 ..................................\n",
      "[CV] ................... C=1.49816047538945, penalty=l2, total=   0.0s\n",
      "[CV] C=1.49816047538945, penalty=l2 ..................................\n",
      "[CV] ................... C=1.49816047538945, penalty=l2, total=   0.0s\n",
      "[CV] C=1.49816047538945, penalty=l2 ..................................\n",
      "[CV] ................... C=1.49816047538945, penalty=l2, total=   0.0s\n",
      "[CV] C=1.49816047538945, penalty=l2 ..................................\n",
      "[CV] ................... C=1.49816047538945, penalty=l2, total=   0.0s\n",
      "[CV] C=0.7337391594646552, penalty=l1 ................................\n",
      "[CV] ................. C=0.7337391594646552, penalty=l1, total=   0.0s\n",
      "[CV] C=0.7337391594646552, penalty=l1 ................................\n",
      "[CV] ................. C=0.7337391594646552, penalty=l1, total=   0.0s\n",
      "[CV] C=0.7337391594646552, penalty=l1 ................................\n",
      "[CV] ................. C=0.7337391594646552, penalty=l1, total=   0.0s\n",
      "[CV] C=0.7337391594646552, penalty=l1 ................................\n",
      "[CV] ................. C=0.7337391594646552, penalty=l1, total=   0.0s\n",
      "[CV] C=0.7337391594646552, penalty=l1 ................................\n",
      "[CV] ................. C=0.7337391594646552, penalty=l1, total=   0.0s\n",
      "[CV] C=2.3946339367881464, penalty=l2 ................................\n",
      "[CV] ................. C=2.3946339367881464, penalty=l2, total=   0.0s\n",
      "[CV] C=2.3946339367881464, penalty=l2 ................................\n",
      "[CV] ................. C=2.3946339367881464, penalty=l2, total=   0.0s\n",
      "[CV] C=2.3946339367881464, penalty=l2 ................................\n",
      "[CV] ................. C=2.3946339367881464, penalty=l2, total=   0.0s\n",
      "[CV] C=2.3946339367881464, penalty=l2 ................................\n",
      "[CV] ................. C=2.3946339367881464, penalty=l2, total=   0.0s\n",
      "[CV] C=2.3946339367881464, penalty=l2 ................................\n",
      "[CV] ................. C=2.3946339367881464, penalty=l2, total=   0.0s\n",
      "[CV] C=1.7833310114143646, penalty=l2 ................................\n",
      "[CV] ................. C=1.7833310114143646, penalty=l2, total=   0.0s\n",
      "[CV] C=1.7833310114143646, penalty=l2 ................................\n",
      "[CV] ................. C=1.7833310114143646, penalty=l2, total=   0.0s\n",
      "[CV] C=1.7833310114143646, penalty=l2 ................................\n",
      "[CV] ................. C=1.7833310114143646, penalty=l2, total=   0.0s\n",
      "[CV] C=1.7833310114143646, penalty=l2 ................................\n",
      "[CV] ................. C=1.7833310114143646, penalty=l2, total=   0.0s\n",
      "[CV] C=1.7833310114143646, penalty=l2 ................................\n",
      "[CV] ................. C=1.7833310114143646, penalty=l2, total=   0.0s\n",
      "[CV] C=0.23233444867279784, penalty=l1 ...............................\n",
      "[CV] ................ C=0.23233444867279784, penalty=l1, total=   0.0s\n",
      "[CV] C=0.23233444867279784, penalty=l1 ...............................\n",
      "[CV] ................ C=0.23233444867279784, penalty=l1, total=   0.0s\n",
      "[CV] C=0.23233444867279784, penalty=l1 ...............................\n",
      "[CV] ................ C=0.23233444867279784, penalty=l1, total=   0.0s\n",
      "[CV] C=0.23233444867279784, penalty=l1 ...............................\n",
      "[CV] ................ C=0.23233444867279784, penalty=l1, total=   0.0s\n",
      "[CV] C=0.23233444867279784, penalty=l1 ...............................\n",
      "[CV] ................ C=0.23233444867279784, penalty=l1, total=   0.0s\n",
      "[CV] C=1.3348344445560874, penalty=l1 ................................\n",
      "[CV] ................. C=1.3348344445560874, penalty=l1, total=   0.0s\n",
      "[CV] C=1.3348344445560874, penalty=l1 ................................\n",
      "[CV] ................. C=1.3348344445560874, penalty=l1, total=   0.0s\n",
      "[CV] C=1.3348344445560874, penalty=l1 ................................\n",
      "[CV] ................. C=1.3348344445560874, penalty=l1, total=   0.0s\n",
      "[CV] C=1.3348344445560874, penalty=l1 ................................\n",
      "[CV] ................. C=1.3348344445560874, penalty=l1, total=   0.0s\n",
      "[CV] C=1.3348344445560874, penalty=l1 ................................\n",
      "[CV] ................. C=1.3348344445560874, penalty=l1, total=   0.0s\n",
      "[CV] C=2.832290311184182, penalty=l1 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=2.832290311184182, penalty=l1, total=   0.0s\n",
      "[CV] C=2.832290311184182, penalty=l1 .................................\n",
      "[CV] .................. C=2.832290311184182, penalty=l1, total=   0.0s\n",
      "[CV] C=2.832290311184182, penalty=l1 .................................\n",
      "[CV] .................. C=2.832290311184182, penalty=l1, total=   0.0s\n",
      "[CV] C=2.832290311184182, penalty=l1 .................................\n",
      "[CV] .................. C=2.832290311184182, penalty=l1, total=   0.0s\n",
      "[CV] C=2.832290311184182, penalty=l1 .................................\n",
      "[CV] .................. C=2.832290311184182, penalty=l1, total=   0.0s\n",
      "[CV] C=0.22564631610840102, penalty=l1 ...............................\n",
      "[CV] ................ C=0.22564631610840102, penalty=l1, total=   0.0s\n",
      "[CV] C=0.22564631610840102, penalty=l1 ...............................\n",
      "[CV] ................ C=0.22564631610840102, penalty=l1, total=   0.0s\n",
      "[CV] C=0.22564631610840102, penalty=l1 ...............................\n",
      "[CV] ................ C=0.22564631610840102, penalty=l1, total=   0.0s\n",
      "[CV] C=0.22564631610840102, penalty=l1 ...............................\n",
      "[CV] ................ C=0.22564631610840102, penalty=l1, total=   0.0s\n",
      "[CV] C=0.22564631610840102, penalty=l1 ...............................\n",
      "[CV] ................ C=0.22564631610840102, penalty=l1, total=   0.0s\n",
      "[CV] C=3.329770563201687, penalty=l1 .................................\n",
      "[CV] .................. C=3.329770563201687, penalty=l1, total=   0.0s\n",
      "[CV] C=3.329770563201687, penalty=l1 .................................\n",
      "[CV] .................. C=3.329770563201687, penalty=l1, total=   0.0s\n",
      "[CV] C=3.329770563201687, penalty=l1 .................................\n",
      "[CV] .................. C=3.329770563201687, penalty=l1, total=   0.0s\n",
      "[CV] C=3.329770563201687, penalty=l1 .................................\n",
      "[CV] .................. C=3.329770563201687, penalty=l1, total=   0.0s\n",
      "[CV] C=3.329770563201687, penalty=l1 .................................\n",
      "[CV] .................. C=3.329770563201687, penalty=l1, total=   0.0s\n",
      "[CV] C=0.0031150633640573133, penalty=l1 .............................\n",
      "[CV] .............. C=0.0031150633640573133, penalty=l1, total=   0.0s\n",
      "[CV] C=0.0031150633640573133, penalty=l1 .............................\n",
      "[CV] .............. C=0.0031150633640573133, penalty=l1, total=   0.0s\n",
      "[CV] C=0.0031150633640573133, penalty=l1 .............................\n",
      "[CV] .............. C=0.0031150633640573133, penalty=l1, total=   0.0s\n",
      "[CV] C=0.0031150633640573133, penalty=l1 .............................\n",
      "[CV] .............. C=0.0031150633640573133, penalty=l1, total=   0.0s\n",
      "[CV] C=0.0031150633640573133, penalty=l1 .............................\n",
      "[CV] .............. C=0.0031150633640573133, penalty=l1, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'C': 0.7337391594646552, 'penalty': 'l1'}, 0.8362421640859141)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Randomized_search_CV for Logistic Regression\n",
    "\n",
    "logistic = LogisticRegression(class_weight='balanced',solver='saga', max_iter=200,\n",
    "                              random_state=42)\n",
    "distributions = dict(C=uniform(loc=0, scale=4),\n",
    "                    penalty=['l2', 'l1'])\n",
    "clf = RandomizedSearchCV(logistic, distributions,scoring='roc_auc',cv=5,verbose=2, random_state=42)\n",
    "search = clf.fit(X_train_scale, y_train)\n",
    "search.best_params_,search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   25.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 52,\n",
       "  'min_samples_split': 2,\n",
       "  'min_samples_leaf': 4,\n",
       "  'max_features': 'auto',\n",
       "  'max_depth': 40,\n",
       "  'bootstrap': True},\n",
       " 0.8478989135864136)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Randomized_search_CV for Random Forest\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 200, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rf = RandomForestClassifier(class_weight='balanced')\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,scoring='roc_auc', n_iter = 100,cv=5,  verbose=2, random_state=42, n_jobs = -1)\n",
    "search_rf=rf_random.fit(X_train, y_train)\n",
    "search_rf.best_params_,search_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] subsample=0.9, reg_lambda=0.5, n_estimators=157, min_child_weight=5.0, max_depth=1, learning_rate=0.001, gamma=0.5, colsample_bytree=0.7, colsample_bylevel=0.9 \n",
      "[12:08:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.9, reg_lambda=0.5, n_estimators=157, min_child_weight=5.0, max_depth=1, learning_rate=0.001, gamma=0.5, colsample_bytree=0.7, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=0.9, reg_lambda=0.5, n_estimators=157, min_child_weight=5.0, max_depth=1, learning_rate=0.001, gamma=0.5, colsample_bytree=0.7, colsample_bylevel=0.9 \n",
      "[12:08:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.9, reg_lambda=0.5, n_estimators=157, min_child_weight=5.0, max_depth=1, learning_rate=0.001, gamma=0.5, colsample_bytree=0.7, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=0.9, reg_lambda=0.5, n_estimators=157, min_child_weight=5.0, max_depth=1, learning_rate=0.001, gamma=0.5, colsample_bytree=0.7, colsample_bylevel=0.9 \n",
      "[12:08:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.9, reg_lambda=0.5, n_estimators=157, min_child_weight=5.0, max_depth=1, learning_rate=0.001, gamma=0.5, colsample_bytree=0.7, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=0.9, reg_lambda=0.5, n_estimators=157, min_child_weight=5.0, max_depth=1, learning_rate=0.001, gamma=0.5, colsample_bytree=0.7, colsample_bylevel=0.9 \n",
      "[12:08:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.9, reg_lambda=0.5, n_estimators=157, min_child_weight=5.0, max_depth=1, learning_rate=0.001, gamma=0.5, colsample_bytree=0.7, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=0.9, reg_lambda=0.5, n_estimators=157, min_child_weight=5.0, max_depth=1, learning_rate=0.001, gamma=0.5, colsample_bytree=0.7, colsample_bylevel=0.9 \n",
      "[12:08:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.9, reg_lambda=0.5, n_estimators=157, min_child_weight=5.0, max_depth=1, learning_rate=0.001, gamma=0.5, colsample_bytree=0.7, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=0.6, reg_lambda=0.5, n_estimators=157, min_child_weight=3.0, max_depth=1, learning_rate=0.01, gamma=0, colsample_bytree=1.0, colsample_bylevel=1.0 \n",
      "[12:08:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.6, reg_lambda=0.5, n_estimators=157, min_child_weight=3.0, max_depth=1, learning_rate=0.01, gamma=0, colsample_bytree=1.0, colsample_bylevel=1.0, total=   0.0s\n",
      "[CV] subsample=0.6, reg_lambda=0.5, n_estimators=157, min_child_weight=3.0, max_depth=1, learning_rate=0.01, gamma=0, colsample_bytree=1.0, colsample_bylevel=1.0 \n",
      "[12:08:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.6, reg_lambda=0.5, n_estimators=157, min_child_weight=3.0, max_depth=1, learning_rate=0.01, gamma=0, colsample_bytree=1.0, colsample_bylevel=1.0, total=   0.0s\n",
      "[CV] subsample=0.6, reg_lambda=0.5, n_estimators=157, min_child_weight=3.0, max_depth=1, learning_rate=0.01, gamma=0, colsample_bytree=1.0, colsample_bylevel=1.0 \n",
      "[12:08:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.6, reg_lambda=0.5, n_estimators=157, min_child_weight=3.0, max_depth=1, learning_rate=0.01, gamma=0, colsample_bytree=1.0, colsample_bylevel=1.0, total=   0.0s\n",
      "[CV] subsample=0.6, reg_lambda=0.5, n_estimators=157, min_child_weight=3.0, max_depth=1, learning_rate=0.01, gamma=0, colsample_bytree=1.0, colsample_bylevel=1.0 \n",
      "[12:08:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.6, reg_lambda=0.5, n_estimators=157, min_child_weight=3.0, max_depth=1, learning_rate=0.01, gamma=0, colsample_bytree=1.0, colsample_bylevel=1.0, total=   0.0s\n",
      "[CV] subsample=0.6, reg_lambda=0.5, n_estimators=157, min_child_weight=3.0, max_depth=1, learning_rate=0.01, gamma=0, colsample_bytree=1.0, colsample_bylevel=1.0 \n",
      "[12:08:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.6, reg_lambda=0.5, n_estimators=157, min_child_weight=3.0, max_depth=1, learning_rate=0.01, gamma=0, colsample_bytree=1.0, colsample_bylevel=1.0, total=   0.0s\n",
      "[CV] subsample=0.7, reg_lambda=0.01, n_estimators=157, min_child_weight=7.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.7, colsample_bylevel=0.9 \n",
      "[12:08:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.7, reg_lambda=0.01, n_estimators=157, min_child_weight=7.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.7, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=0.7, reg_lambda=0.01, n_estimators=157, min_child_weight=7.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.7, colsample_bylevel=0.9 \n",
      "[12:08:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.7, reg_lambda=0.01, n_estimators=157, min_child_weight=7.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.7, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=0.7, reg_lambda=0.01, n_estimators=157, min_child_weight=7.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.7, colsample_bylevel=0.9 \n",
      "[12:08:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.7, reg_lambda=0.01, n_estimators=157, min_child_weight=7.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.7, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=0.7, reg_lambda=0.01, n_estimators=157, min_child_weight=7.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.7, colsample_bylevel=0.9 \n",
      "[12:08:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.7, reg_lambda=0.01, n_estimators=157, min_child_weight=7.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.7, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=0.7, reg_lambda=0.01, n_estimators=157, min_child_weight=7.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.7, colsample_bylevel=0.9 \n",
      "[12:08:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.7, reg_lambda=0.01, n_estimators=157, min_child_weight=7.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.7, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=0.5, reg_lambda=0.05, n_estimators=178, min_child_weight=7.0, max_depth=1, learning_rate=0.2, gamma=1.0, colsample_bytree=0.9, colsample_bylevel=0.9 \n",
      "[12:08:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.5, reg_lambda=0.05, n_estimators=178, min_child_weight=7.0, max_depth=1, learning_rate=0.2, gamma=1.0, colsample_bytree=0.9, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=0.5, reg_lambda=0.05, n_estimators=178, min_child_weight=7.0, max_depth=1, learning_rate=0.2, gamma=1.0, colsample_bytree=0.9, colsample_bylevel=0.9 \n",
      "[12:08:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.5, reg_lambda=0.05, n_estimators=178, min_child_weight=7.0, max_depth=1, learning_rate=0.2, gamma=1.0, colsample_bytree=0.9, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=0.5, reg_lambda=0.05, n_estimators=178, min_child_weight=7.0, max_depth=1, learning_rate=0.2, gamma=1.0, colsample_bytree=0.9, colsample_bylevel=0.9 \n",
      "[12:08:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  subsample=0.5, reg_lambda=0.05, n_estimators=178, min_child_weight=7.0, max_depth=1, learning_rate=0.2, gamma=1.0, colsample_bytree=0.9, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=0.5, reg_lambda=0.05, n_estimators=178, min_child_weight=7.0, max_depth=1, learning_rate=0.2, gamma=1.0, colsample_bytree=0.9, colsample_bylevel=0.9 \n",
      "[12:08:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.5, reg_lambda=0.05, n_estimators=178, min_child_weight=7.0, max_depth=1, learning_rate=0.2, gamma=1.0, colsample_bytree=0.9, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=0.5, reg_lambda=0.05, n_estimators=178, min_child_weight=7.0, max_depth=1, learning_rate=0.2, gamma=1.0, colsample_bytree=0.9, colsample_bylevel=0.9 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:08:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.5, reg_lambda=0.05, n_estimators=178, min_child_weight=7.0, max_depth=1, learning_rate=0.2, gamma=1.0, colsample_bytree=0.9, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=1.0, reg_lambda=0.1, n_estimators=178, min_child_weight=1.0, max_depth=1, learning_rate=0.2, gamma=0.25, colsample_bytree=0.5, colsample_bylevel=0.8 \n",
      "[12:08:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=1.0, reg_lambda=0.1, n_estimators=178, min_child_weight=1.0, max_depth=1, learning_rate=0.2, gamma=0.25, colsample_bytree=0.5, colsample_bylevel=0.8, total=   0.0s\n",
      "[CV] subsample=1.0, reg_lambda=0.1, n_estimators=178, min_child_weight=1.0, max_depth=1, learning_rate=0.2, gamma=0.25, colsample_bytree=0.5, colsample_bylevel=0.8 \n",
      "[12:08:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=1.0, reg_lambda=0.1, n_estimators=178, min_child_weight=1.0, max_depth=1, learning_rate=0.2, gamma=0.25, colsample_bytree=0.5, colsample_bylevel=0.8, total=   0.0s\n",
      "[CV] subsample=1.0, reg_lambda=0.1, n_estimators=178, min_child_weight=1.0, max_depth=1, learning_rate=0.2, gamma=0.25, colsample_bytree=0.5, colsample_bylevel=0.8 \n",
      "[12:08:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=1.0, reg_lambda=0.1, n_estimators=178, min_child_weight=1.0, max_depth=1, learning_rate=0.2, gamma=0.25, colsample_bytree=0.5, colsample_bylevel=0.8, total=   0.0s\n",
      "[CV] subsample=1.0, reg_lambda=0.1, n_estimators=178, min_child_weight=1.0, max_depth=1, learning_rate=0.2, gamma=0.25, colsample_bytree=0.5, colsample_bylevel=0.8 \n",
      "[12:08:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=1.0, reg_lambda=0.1, n_estimators=178, min_child_weight=1.0, max_depth=1, learning_rate=0.2, gamma=0.25, colsample_bytree=0.5, colsample_bylevel=0.8, total=   0.0s\n",
      "[CV] subsample=1.0, reg_lambda=0.1, n_estimators=178, min_child_weight=1.0, max_depth=1, learning_rate=0.2, gamma=0.25, colsample_bytree=0.5, colsample_bylevel=0.8 \n",
      "[12:08:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=1.0, reg_lambda=0.1, n_estimators=178, min_child_weight=1.0, max_depth=1, learning_rate=0.2, gamma=0.25, colsample_bytree=0.5, colsample_bylevel=0.8, total=   0.0s\n",
      "[CV] subsample=0.7, reg_lambda=0.5, n_estimators=136, min_child_weight=10.0, max_depth=1, learning_rate=0.2, gamma=1.0, colsample_bytree=0.5, colsample_bylevel=0.4 \n",
      "[12:08:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.7, reg_lambda=0.5, n_estimators=136, min_child_weight=10.0, max_depth=1, learning_rate=0.2, gamma=1.0, colsample_bytree=0.5, colsample_bylevel=0.4, total=   0.0s\n",
      "[CV] subsample=0.7, reg_lambda=0.5, n_estimators=136, min_child_weight=10.0, max_depth=1, learning_rate=0.2, gamma=1.0, colsample_bytree=0.5, colsample_bylevel=0.4 \n",
      "[12:08:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.7, reg_lambda=0.5, n_estimators=136, min_child_weight=10.0, max_depth=1, learning_rate=0.2, gamma=1.0, colsample_bytree=0.5, colsample_bylevel=0.4, total=   0.0s\n",
      "[CV] subsample=0.7, reg_lambda=0.5, n_estimators=136, min_child_weight=10.0, max_depth=1, learning_rate=0.2, gamma=1.0, colsample_bytree=0.5, colsample_bylevel=0.4 \n",
      "[12:08:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.7, reg_lambda=0.5, n_estimators=136, min_child_weight=10.0, max_depth=1, learning_rate=0.2, gamma=1.0, colsample_bytree=0.5, colsample_bylevel=0.4, total=   0.0s\n",
      "[CV] subsample=0.7, reg_lambda=0.5, n_estimators=136, min_child_weight=10.0, max_depth=1, learning_rate=0.2, gamma=1.0, colsample_bytree=0.5, colsample_bylevel=0.4 \n",
      "[12:08:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.7, reg_lambda=0.5, n_estimators=136, min_child_weight=10.0, max_depth=1, learning_rate=0.2, gamma=1.0, colsample_bytree=0.5, colsample_bylevel=0.4, total=   0.0s\n",
      "[CV] subsample=0.7, reg_lambda=0.5, n_estimators=136, min_child_weight=10.0, max_depth=1, learning_rate=0.2, gamma=1.0, colsample_bytree=0.5, colsample_bylevel=0.4 \n",
      "[12:08:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.7, reg_lambda=0.5, n_estimators=136, min_child_weight=10.0, max_depth=1, learning_rate=0.2, gamma=1.0, colsample_bytree=0.5, colsample_bylevel=0.4, total=   0.0s\n",
      "[CV] subsample=0.7, reg_lambda=0.1, n_estimators=94, min_child_weight=0.5, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.5 \n",
      "[12:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.7, reg_lambda=0.1, n_estimators=94, min_child_weight=0.5, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.5, total=   0.0s\n",
      "[CV] subsample=0.7, reg_lambda=0.1, n_estimators=94, min_child_weight=0.5, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.5 \n",
      "[12:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.7, reg_lambda=0.1, n_estimators=94, min_child_weight=0.5, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.5, total=   0.0s\n",
      "[CV] subsample=0.7, reg_lambda=0.1, n_estimators=94, min_child_weight=0.5, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.5 \n",
      "[12:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.7, reg_lambda=0.1, n_estimators=94, min_child_weight=0.5, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.5, total=   0.0s\n",
      "[CV] subsample=0.7, reg_lambda=0.1, n_estimators=94, min_child_weight=0.5, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.5 \n",
      "[12:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.7, reg_lambda=0.1, n_estimators=94, min_child_weight=0.5, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.5, total=   0.0s\n",
      "[CV] subsample=0.7, reg_lambda=0.1, n_estimators=94, min_child_weight=0.5, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.5 \n",
      "[12:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.7, reg_lambda=0.1, n_estimators=94, min_child_weight=0.5, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.5, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] subsample=0.4, reg_lambda=0.05, n_estimators=52, min_child_weight=0.5, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.7, colsample_bylevel=0.9 \n",
      "[12:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.4, reg_lambda=0.05, n_estimators=52, min_child_weight=0.5, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.7, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=0.4, reg_lambda=0.05, n_estimators=52, min_child_weight=0.5, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.7, colsample_bylevel=0.9 \n",
      "[12:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.4, reg_lambda=0.05, n_estimators=52, min_child_weight=0.5, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.7, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=0.4, reg_lambda=0.05, n_estimators=52, min_child_weight=0.5, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.7, colsample_bylevel=0.9 \n",
      "[12:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.4, reg_lambda=0.05, n_estimators=52, min_child_weight=0.5, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.7, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=0.4, reg_lambda=0.05, n_estimators=52, min_child_weight=0.5, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.7, colsample_bylevel=0.9 \n",
      "[12:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.4, reg_lambda=0.05, n_estimators=52, min_child_weight=0.5, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.7, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=0.4, reg_lambda=0.05, n_estimators=52, min_child_weight=0.5, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.7, colsample_bylevel=0.9 \n",
      "[12:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.4, reg_lambda=0.05, n_estimators=52, min_child_weight=0.5, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.7, colsample_bylevel=0.9, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] subsample=0.9, reg_lambda=0.01, n_estimators=10, min_child_weight=1.0, max_depth=1, learning_rate=0.001, gamma=0.25, colsample_bytree=1.0, colsample_bylevel=0.7 \n",
      "[12:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.9, reg_lambda=0.01, n_estimators=10, min_child_weight=1.0, max_depth=1, learning_rate=0.001, gamma=0.25, colsample_bytree=1.0, colsample_bylevel=0.7, total=   0.0s\n",
      "[CV] subsample=0.9, reg_lambda=0.01, n_estimators=10, min_child_weight=1.0, max_depth=1, learning_rate=0.001, gamma=0.25, colsample_bytree=1.0, colsample_bylevel=0.7 \n",
      "[12:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.9, reg_lambda=0.01, n_estimators=10, min_child_weight=1.0, max_depth=1, learning_rate=0.001, gamma=0.25, colsample_bytree=1.0, colsample_bylevel=0.7, total=   0.0s\n",
      "[CV] subsample=0.9, reg_lambda=0.01, n_estimators=10, min_child_weight=1.0, max_depth=1, learning_rate=0.001, gamma=0.25, colsample_bytree=1.0, colsample_bylevel=0.7 \n",
      "[12:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.9, reg_lambda=0.01, n_estimators=10, min_child_weight=1.0, max_depth=1, learning_rate=0.001, gamma=0.25, colsample_bytree=1.0, colsample_bylevel=0.7, total=   0.0s\n",
      "[CV] subsample=0.9, reg_lambda=0.01, n_estimators=10, min_child_weight=1.0, max_depth=1, learning_rate=0.001, gamma=0.25, colsample_bytree=1.0, colsample_bylevel=0.7 \n",
      "[12:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.9, reg_lambda=0.01, n_estimators=10, min_child_weight=1.0, max_depth=1, learning_rate=0.001, gamma=0.25, colsample_bytree=1.0, colsample_bylevel=0.7, total=   0.0s\n",
      "[CV] subsample=0.9, reg_lambda=0.01, n_estimators=10, min_child_weight=1.0, max_depth=1, learning_rate=0.001, gamma=0.25, colsample_bytree=1.0, colsample_bylevel=0.7 \n",
      "[12:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.9, reg_lambda=0.01, n_estimators=10, min_child_weight=1.0, max_depth=1, learning_rate=0.001, gamma=0.25, colsample_bytree=1.0, colsample_bylevel=0.7, total=   0.0s\n",
      "[CV] subsample=0.5, reg_lambda=1, n_estimators=31, min_child_weight=7.0, max_depth=1, learning_rate=0.001, gamma=1.0, colsample_bytree=1.0, colsample_bylevel=0.8 \n",
      "[12:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.5, reg_lambda=1, n_estimators=31, min_child_weight=7.0, max_depth=1, learning_rate=0.001, gamma=1.0, colsample_bytree=1.0, colsample_bylevel=0.8, total=   0.0s\n",
      "[CV] subsample=0.5, reg_lambda=1, n_estimators=31, min_child_weight=7.0, max_depth=1, learning_rate=0.001, gamma=1.0, colsample_bytree=1.0, colsample_bylevel=0.8 \n",
      "[12:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.5, reg_lambda=1, n_estimators=31, min_child_weight=7.0, max_depth=1, learning_rate=0.001, gamma=1.0, colsample_bytree=1.0, colsample_bylevel=0.8, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] subsample=0.5, reg_lambda=1, n_estimators=31, min_child_weight=7.0, max_depth=1, learning_rate=0.001, gamma=1.0, colsample_bytree=1.0, colsample_bylevel=0.8 \n",
      "[12:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.5, reg_lambda=1, n_estimators=31, min_child_weight=7.0, max_depth=1, learning_rate=0.001, gamma=1.0, colsample_bytree=1.0, colsample_bylevel=0.8, total=   0.0s\n",
      "[CV] subsample=0.5, reg_lambda=1, n_estimators=31, min_child_weight=7.0, max_depth=1, learning_rate=0.001, gamma=1.0, colsample_bytree=1.0, colsample_bylevel=0.8 \n",
      "[12:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.5, reg_lambda=1, n_estimators=31, min_child_weight=7.0, max_depth=1, learning_rate=0.001, gamma=1.0, colsample_bytree=1.0, colsample_bylevel=0.8, total=   0.0s\n",
      "[CV] subsample=0.5, reg_lambda=1, n_estimators=31, min_child_weight=7.0, max_depth=1, learning_rate=0.001, gamma=1.0, colsample_bytree=1.0, colsample_bylevel=0.8 \n",
      "[12:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.5, reg_lambda=1, n_estimators=31, min_child_weight=7.0, max_depth=1, learning_rate=0.001, gamma=1.0, colsample_bytree=1.0, colsample_bylevel=0.8, total=   0.0s\n",
      "[CV] subsample=0.5, reg_lambda=1, n_estimators=31, min_child_weight=3.0, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.6 \n",
      "[12:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.5, reg_lambda=1, n_estimators=31, min_child_weight=3.0, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.6, total=   0.0s\n",
      "[CV] subsample=0.5, reg_lambda=1, n_estimators=31, min_child_weight=3.0, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.6 \n",
      "[12:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.5, reg_lambda=1, n_estimators=31, min_child_weight=3.0, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.6, total=   0.0s\n",
      "[CV] subsample=0.5, reg_lambda=1, n_estimators=31, min_child_weight=3.0, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.6 \n",
      "[12:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.5, reg_lambda=1, n_estimators=31, min_child_weight=3.0, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.6, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] subsample=0.5, reg_lambda=1, n_estimators=31, min_child_weight=3.0, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.6 \n",
      "[12:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.5, reg_lambda=1, n_estimators=31, min_child_weight=3.0, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.6, total=   0.0s\n",
      "[CV] subsample=0.5, reg_lambda=1, n_estimators=31, min_child_weight=3.0, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.6 \n",
      "[12:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.5, reg_lambda=1, n_estimators=31, min_child_weight=3.0, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.6, total=   0.0s\n",
      "[CV] subsample=0.6, reg_lambda=1, n_estimators=178, min_child_weight=7.0, max_depth=1, learning_rate=0, gamma=0.25, colsample_bytree=0.8, colsample_bylevel=0.9 \n",
      "[12:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.6, reg_lambda=1, n_estimators=178, min_child_weight=7.0, max_depth=1, learning_rate=0, gamma=0.25, colsample_bytree=0.8, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=0.6, reg_lambda=1, n_estimators=178, min_child_weight=7.0, max_depth=1, learning_rate=0, gamma=0.25, colsample_bytree=0.8, colsample_bylevel=0.9 \n",
      "[12:08:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.6, reg_lambda=1, n_estimators=178, min_child_weight=7.0, max_depth=1, learning_rate=0, gamma=0.25, colsample_bytree=0.8, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=0.6, reg_lambda=1, n_estimators=178, min_child_weight=7.0, max_depth=1, learning_rate=0, gamma=0.25, colsample_bytree=0.8, colsample_bylevel=0.9 \n",
      "[12:08:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.6, reg_lambda=1, n_estimators=178, min_child_weight=7.0, max_depth=1, learning_rate=0, gamma=0.25, colsample_bytree=0.8, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=0.6, reg_lambda=1, n_estimators=178, min_child_weight=7.0, max_depth=1, learning_rate=0, gamma=0.25, colsample_bytree=0.8, colsample_bylevel=0.9 \n",
      "[12:08:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.6, reg_lambda=1, n_estimators=178, min_child_weight=7.0, max_depth=1, learning_rate=0, gamma=0.25, colsample_bytree=0.8, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=0.6, reg_lambda=1, n_estimators=178, min_child_weight=7.0, max_depth=1, learning_rate=0, gamma=0.25, colsample_bytree=0.8, colsample_bylevel=0.9 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:08:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.6, reg_lambda=1, n_estimators=178, min_child_weight=7.0, max_depth=1, learning_rate=0, gamma=0.25, colsample_bytree=0.8, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=1.0, reg_lambda=0.5, n_estimators=157, min_child_weight=5.0, max_depth=1, learning_rate=0.001, gamma=0.5, colsample_bytree=0.4, colsample_bylevel=0.7 \n",
      "[12:08:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=1.0, reg_lambda=0.5, n_estimators=157, min_child_weight=5.0, max_depth=1, learning_rate=0.001, gamma=0.5, colsample_bytree=0.4, colsample_bylevel=0.7, total=   0.0s\n",
      "[CV] subsample=1.0, reg_lambda=0.5, n_estimators=157, min_child_weight=5.0, max_depth=1, learning_rate=0.001, gamma=0.5, colsample_bytree=0.4, colsample_bylevel=0.7 \n",
      "[12:08:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=1.0, reg_lambda=0.5, n_estimators=157, min_child_weight=5.0, max_depth=1, learning_rate=0.001, gamma=0.5, colsample_bytree=0.4, colsample_bylevel=0.7, total=   0.0s\n",
      "[CV] subsample=1.0, reg_lambda=0.5, n_estimators=157, min_child_weight=5.0, max_depth=1, learning_rate=0.001, gamma=0.5, colsample_bytree=0.4, colsample_bylevel=0.7 \n",
      "[12:08:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=1.0, reg_lambda=0.5, n_estimators=157, min_child_weight=5.0, max_depth=1, learning_rate=0.001, gamma=0.5, colsample_bytree=0.4, colsample_bylevel=0.7, total=   0.0s\n",
      "[CV] subsample=1.0, reg_lambda=0.5, n_estimators=157, min_child_weight=5.0, max_depth=1, learning_rate=0.001, gamma=0.5, colsample_bytree=0.4, colsample_bylevel=0.7 \n",
      "[12:08:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=1.0, reg_lambda=0.5, n_estimators=157, min_child_weight=5.0, max_depth=1, learning_rate=0.001, gamma=0.5, colsample_bytree=0.4, colsample_bylevel=0.7, total=   0.0s\n",
      "[CV] subsample=1.0, reg_lambda=0.5, n_estimators=157, min_child_weight=5.0, max_depth=1, learning_rate=0.001, gamma=0.5, colsample_bytree=0.4, colsample_bylevel=0.7 \n",
      "[12:08:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=1.0, reg_lambda=0.5, n_estimators=157, min_child_weight=5.0, max_depth=1, learning_rate=0.001, gamma=0.5, colsample_bytree=0.4, colsample_bylevel=0.7, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] subsample=1.0, reg_lambda=0.01, n_estimators=94, min_child_weight=10.0, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.8, colsample_bylevel=0.4 \n",
      "[12:08:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=1.0, reg_lambda=0.01, n_estimators=94, min_child_weight=10.0, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.8, colsample_bylevel=0.4, total=   0.0s\n",
      "[CV] subsample=1.0, reg_lambda=0.01, n_estimators=94, min_child_weight=10.0, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.8, colsample_bylevel=0.4 \n",
      "[12:08:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=1.0, reg_lambda=0.01, n_estimators=94, min_child_weight=10.0, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.8, colsample_bylevel=0.4, total=   0.0s\n",
      "[CV] subsample=1.0, reg_lambda=0.01, n_estimators=94, min_child_weight=10.0, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.8, colsample_bylevel=0.4 \n",
      "[12:08:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=1.0, reg_lambda=0.01, n_estimators=94, min_child_weight=10.0, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.8, colsample_bylevel=0.4, total=   0.0s\n",
      "[CV] subsample=1.0, reg_lambda=0.01, n_estimators=94, min_child_weight=10.0, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.8, colsample_bylevel=0.4 \n",
      "[12:08:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=1.0, reg_lambda=0.01, n_estimators=94, min_child_weight=10.0, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.8, colsample_bylevel=0.4, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] subsample=1.0, reg_lambda=0.01, n_estimators=94, min_child_weight=10.0, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.8, colsample_bylevel=0.4 \n",
      "[12:08:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=1.0, reg_lambda=0.01, n_estimators=94, min_child_weight=10.0, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.8, colsample_bylevel=0.4, total=   0.0s\n",
      "[CV] subsample=0.5, reg_lambda=0.01, n_estimators=136, min_child_weight=10.0, max_depth=1, learning_rate=0.1, gamma=0, colsample_bytree=0.6, colsample_bylevel=0.9 \n",
      "[12:08:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.5, reg_lambda=0.01, n_estimators=136, min_child_weight=10.0, max_depth=1, learning_rate=0.1, gamma=0, colsample_bytree=0.6, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=0.5, reg_lambda=0.01, n_estimators=136, min_child_weight=10.0, max_depth=1, learning_rate=0.1, gamma=0, colsample_bytree=0.6, colsample_bylevel=0.9 \n",
      "[12:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.5, reg_lambda=0.01, n_estimators=136, min_child_weight=10.0, max_depth=1, learning_rate=0.1, gamma=0, colsample_bytree=0.6, colsample_bylevel=0.9, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] subsample=0.5, reg_lambda=0.01, n_estimators=136, min_child_weight=10.0, max_depth=1, learning_rate=0.1, gamma=0, colsample_bytree=0.6, colsample_bylevel=0.9 \n",
      "[12:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.5, reg_lambda=0.01, n_estimators=136, min_child_weight=10.0, max_depth=1, learning_rate=0.1, gamma=0, colsample_bytree=0.6, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=0.5, reg_lambda=0.01, n_estimators=136, min_child_weight=10.0, max_depth=1, learning_rate=0.1, gamma=0, colsample_bytree=0.6, colsample_bylevel=0.9 \n",
      "[12:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.5, reg_lambda=0.01, n_estimators=136, min_child_weight=10.0, max_depth=1, learning_rate=0.1, gamma=0, colsample_bytree=0.6, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=0.5, reg_lambda=0.01, n_estimators=136, min_child_weight=10.0, max_depth=1, learning_rate=0.1, gamma=0, colsample_bytree=0.6, colsample_bylevel=0.9 \n",
      "[12:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.5, reg_lambda=0.01, n_estimators=136, min_child_weight=10.0, max_depth=1, learning_rate=0.1, gamma=0, colsample_bytree=0.6, colsample_bylevel=0.9, total=   0.0s\n",
      "[CV] subsample=0.8, reg_lambda=0.01, n_estimators=94, min_child_weight=1.0, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.4 \n",
      "[12:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.8, reg_lambda=0.01, n_estimators=94, min_child_weight=1.0, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.4, total=   0.0s\n",
      "[CV] subsample=0.8, reg_lambda=0.01, n_estimators=94, min_child_weight=1.0, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.4 \n",
      "[12:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.8, reg_lambda=0.01, n_estimators=94, min_child_weight=1.0, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.4, total=   0.0s\n",
      "[CV] subsample=0.8, reg_lambda=0.01, n_estimators=94, min_child_weight=1.0, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.4 \n",
      "[12:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.8, reg_lambda=0.01, n_estimators=94, min_child_weight=1.0, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.4, total=   0.0s\n",
      "[CV] subsample=0.8, reg_lambda=0.01, n_estimators=94, min_child_weight=1.0, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.4 \n",
      "[12:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.8, reg_lambda=0.01, n_estimators=94, min_child_weight=1.0, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.4, total=   0.0s\n",
      "[CV] subsample=0.8, reg_lambda=0.01, n_estimators=94, min_child_weight=1.0, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.4 \n",
      "[12:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.8, reg_lambda=0.01, n_estimators=94, min_child_weight=1.0, max_depth=1, learning_rate=3, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.4, total=   0.0s\n",
      "[CV] subsample=0.4, reg_lambda=0.01, n_estimators=10, min_child_weight=0.5, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=1.0, colsample_bylevel=0.5 \n",
      "[12:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.4, reg_lambda=0.01, n_estimators=10, min_child_weight=0.5, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=1.0, colsample_bylevel=0.5, total=   0.0s\n",
      "[CV] subsample=0.4, reg_lambda=0.01, n_estimators=10, min_child_weight=0.5, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=1.0, colsample_bylevel=0.5 \n",
      "[12:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.4, reg_lambda=0.01, n_estimators=10, min_child_weight=0.5, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=1.0, colsample_bylevel=0.5, total=   0.0s\n",
      "[CV] subsample=0.4, reg_lambda=0.01, n_estimators=10, min_child_weight=0.5, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=1.0, colsample_bylevel=0.5 \n",
      "[12:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.4, reg_lambda=0.01, n_estimators=10, min_child_weight=0.5, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=1.0, colsample_bylevel=0.5, total=   0.0s\n",
      "[CV] subsample=0.4, reg_lambda=0.01, n_estimators=10, min_child_weight=0.5, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=1.0, colsample_bylevel=0.5 \n",
      "[12:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.4, reg_lambda=0.01, n_estimators=10, min_child_weight=0.5, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=1.0, colsample_bylevel=0.5, total=   0.0s\n",
      "[CV] subsample=0.4, reg_lambda=0.01, n_estimators=10, min_child_weight=0.5, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=1.0, colsample_bylevel=0.5 \n",
      "[12:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.4, reg_lambda=0.01, n_estimators=10, min_child_weight=0.5, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=1.0, colsample_bylevel=0.5, total=   0.0s\n",
      "[CV] subsample=1.0, reg_lambda=0.05, n_estimators=31, min_child_weight=0.5, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.6, colsample_bylevel=0.7 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=1.0, reg_lambda=0.05, n_estimators=31, min_child_weight=0.5, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.6, colsample_bylevel=0.7, total=   0.0s\n",
      "[CV] subsample=1.0, reg_lambda=0.05, n_estimators=31, min_child_weight=0.5, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.6, colsample_bylevel=0.7 \n",
      "[12:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=1.0, reg_lambda=0.05, n_estimators=31, min_child_weight=0.5, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.6, colsample_bylevel=0.7, total=   0.0s\n",
      "[CV] subsample=1.0, reg_lambda=0.05, n_estimators=31, min_child_weight=0.5, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.6, colsample_bylevel=0.7 \n",
      "[12:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=1.0, reg_lambda=0.05, n_estimators=31, min_child_weight=0.5, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.6, colsample_bylevel=0.7, total=   0.0s\n",
      "[CV] subsample=1.0, reg_lambda=0.05, n_estimators=31, min_child_weight=0.5, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.6, colsample_bylevel=0.7 \n",
      "[12:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=1.0, reg_lambda=0.05, n_estimators=31, min_child_weight=0.5, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.6, colsample_bylevel=0.7, total=   0.0s\n",
      "[CV] subsample=1.0, reg_lambda=0.05, n_estimators=31, min_child_weight=0.5, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.6, colsample_bylevel=0.7 \n",
      "[12:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=1.0, reg_lambda=0.05, n_estimators=31, min_child_weight=0.5, max_depth=1, learning_rate=0.01, gamma=1.0, colsample_bytree=0.6, colsample_bylevel=0.7, total=   0.0s\n",
      "[CV] subsample=0.6, reg_lambda=0.05, n_estimators=52, min_child_weight=1.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.6, colsample_bylevel=0.8 \n",
      "[12:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.6, reg_lambda=0.05, n_estimators=52, min_child_weight=1.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.6, colsample_bylevel=0.8, total=   0.0s\n",
      "[CV] subsample=0.6, reg_lambda=0.05, n_estimators=52, min_child_weight=1.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.6, colsample_bylevel=0.8 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.6, reg_lambda=0.05, n_estimators=52, min_child_weight=1.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.6, colsample_bylevel=0.8, total=   0.0s\n",
      "[CV] subsample=0.6, reg_lambda=0.05, n_estimators=52, min_child_weight=1.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.6, colsample_bylevel=0.8 \n",
      "[12:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.6, reg_lambda=0.05, n_estimators=52, min_child_weight=1.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.6, colsample_bylevel=0.8, total=   0.0s\n",
      "[CV] subsample=0.6, reg_lambda=0.05, n_estimators=52, min_child_weight=1.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.6, colsample_bylevel=0.8 \n",
      "[12:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.6, reg_lambda=0.05, n_estimators=52, min_child_weight=1.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.6, colsample_bylevel=0.8, total=   0.0s\n",
      "[CV] subsample=0.6, reg_lambda=0.05, n_estimators=52, min_child_weight=1.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.6, colsample_bylevel=0.8 \n",
      "[12:08:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.6, reg_lambda=0.05, n_estimators=52, min_child_weight=1.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.6, colsample_bylevel=0.8, total=   0.0s\n",
      "[CV] subsample=0.8, reg_lambda=0.5, n_estimators=136, min_child_weight=1.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.4 \n",
      "[12:08:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  subsample=0.8, reg_lambda=0.5, n_estimators=136, min_child_weight=1.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.4, total=   0.0s\n",
      "[CV] subsample=0.8, reg_lambda=0.5, n_estimators=136, min_child_weight=1.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.4 \n",
      "[12:08:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.8, reg_lambda=0.5, n_estimators=136, min_child_weight=1.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.4, total=   0.0s\n",
      "[CV] subsample=0.8, reg_lambda=0.5, n_estimators=136, min_child_weight=1.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.4 \n",
      "[12:08:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.8, reg_lambda=0.5, n_estimators=136, min_child_weight=1.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.4, total=   0.0s\n",
      "[CV] subsample=0.8, reg_lambda=0.5, n_estimators=136, min_child_weight=1.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.4 \n",
      "[12:08:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.8, reg_lambda=0.5, n_estimators=136, min_child_weight=1.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.4, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] subsample=0.8, reg_lambda=0.5, n_estimators=136, min_child_weight=1.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.4 \n",
      "[12:08:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]  subsample=0.8, reg_lambda=0.5, n_estimators=136, min_child_weight=1.0, max_depth=1, learning_rate=0, gamma=0.5, colsample_bytree=0.9, colsample_bylevel=0.4, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    5.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'subsample': 1.0,\n",
       "  'reg_lambda': 0.1,\n",
       "  'n_estimators': 178,\n",
       "  'min_child_weight': 1.0,\n",
       "  'max_depth': 1,\n",
       "  'learning_rate': 0.2,\n",
       "  'gamma': 0.25,\n",
       "  'colsample_bytree': 0.5,\n",
       "  'colsample_bylevel': 0.8},\n",
       " 0.8478989135864136)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier()\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 200, num = 10)]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(1, 20, num = 1)]\n",
    "\n",
    "param_grid = {\n",
    "        'max_depth': max_depth,\n",
    "        'learning_rate': [0.001, 0.01, 0.1, 0.2, 0,3],\n",
    "        'subsample': [0.3,0.4,0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bylevel': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'min_child_weight': [0.5, 1.0, 3.0, 5.0, 7.0, 10.0],\n",
    "        'gamma': [0, 0.25, 0.5, 1.0],\n",
    "        'reg_lambda': [0.01, 0.05,0.1,0.5,1],\n",
    "        'n_estimators': n_estimators}\n",
    "\n",
    "\n",
    "xgb_clf = RandomizedSearchCV(clf, param_grid, n_iter=20,cv=5,\n",
    "                            n_jobs=1, verbose=2,\n",
    "                            scoring='roc_auc', refit=False, random_state=42)\n",
    "search_xgb=xgb_clf.fit(X_train, y_train)\n",
    "search_xgb.best_params_,search_rf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observation: random Forest and Xgboost performed on similar Lines with Random Serach CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Test Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv(\"zeta-disease_prediction-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>bmi</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>insulin_test</th>\n",
       "      <th>liver_stress_test</th>\n",
       "      <th>cardio_stress_test</th>\n",
       "      <th>years_smoking</th>\n",
       "      <th>zeta_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>151</td>\n",
       "      <td>39.5</td>\n",
       "      <td>69</td>\n",
       "      <td>72</td>\n",
       "      <td>1.3968</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>179</td>\n",
       "      <td>35.5</td>\n",
       "      <td>89</td>\n",
       "      <td>156</td>\n",
       "      <td>1.6608</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>147</td>\n",
       "      <td>26.9</td>\n",
       "      <td>76</td>\n",
       "      <td>74</td>\n",
       "      <td>1.6958</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>206</td>\n",
       "      <td>32.4</td>\n",
       "      <td>73</td>\n",
       "      <td>127</td>\n",
       "      <td>1.4608</td>\n",
       "      <td>61</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>193</td>\n",
       "      <td>29.8</td>\n",
       "      <td>62</td>\n",
       "      <td>192</td>\n",
       "      <td>1.7798</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  weight   bmi  blood_pressure  insulin_test  liver_stress_test  \\\n",
       "0   24     151  39.5              69            72             1.3968   \n",
       "1   27     179  35.5              89           156             1.6608   \n",
       "2   34     147  26.9              76            74             1.6958   \n",
       "3   35     206  32.4              73           127             1.4608   \n",
       "4   60     193  29.8              62           192             1.7798   \n",
       "\n",
       "   cardio_stress_test  years_smoking  zeta_disease  \n",
       "0                  56              4           NaN  \n",
       "1                  43              6           NaN  \n",
       "2                  53              2           NaN  \n",
       "3                  61              6           NaN  \n",
       "4                  65              9           NaN  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outlier Treatmeant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmi_upper_limit, bmi_lower_limit = find_skewed_boundaries(df_test, 'bmi', 1.5)\n",
    "df_test['bmi']= np.where(df_test['bmi'] > bmi_upper_limit, bmi_upper_limit,\n",
    "                       np.where(df_test['bmi'] < bmi_lower_limit, bmi_lower_limit, df_test['bmi']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "blood_pressure_upper_limit, blood_pressure_lower_limit = find_skewed_boundaries(df_test, 'blood_pressure', 1.5)\n",
    "df_test['bmi']= np.where(df_test['blood_pressure'] > blood_pressure_upper_limit, blood_pressure_upper_limit,\n",
    "                       np.where(df_test['blood_pressure'] < blood_pressure_lower_limit, blood_pressure_lower_limit, df_test['blood_pressure']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.2268, 0.9227999999999998)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liver_stress_test_upper_limit, liver_stress_test_lower_limit = find_skewed_boundaries(df_test, 'liver_stress_test', 1.5)\n",
    "liver_stress_test_upper_limit, liver_stress_test_lower_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305.0, -61.0)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insulin_test_upper_limit, insulin_test_lower_limit = find_skewed_boundaries(df_test, 'insulin_test', 1.5)\n",
    "insulin_test_upper_limit, insulin_test_lower_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "insulin_test_g_upper_limit, insulin_test_g_lower_limit = find_boundaries(df_test, 'insulin_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['liver_stress_test']= np.where(df_test['liver_stress_test'] > liver_stress_test_upper_limit, liver_stress_test_upper_limit,\n",
    "                       np.where(df_test['liver_stress_test'] < liver_stress_test_lower_limit, liver_stress_test_lower_limit, df_test['liver_stress_test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 8), (20,))"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and validation\n",
    "X_test, y_test=df_test.drop(labels=['zeta_disease'],axis=1), df_test['zeta_disease']\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the test dataset for randomforest\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, min_samples_split=2,min_samples_leaf=2,max_features='sqrt',max_depth=20,bootstrap=True,\n",
    "                                random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "predictions_rf = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['zeta_disease']=predictions_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>bmi</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>insulin_test</th>\n",
       "      <th>liver_stress_test</th>\n",
       "      <th>cardio_stress_test</th>\n",
       "      <th>years_smoking</th>\n",
       "      <th>zeta_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>151</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69</td>\n",
       "      <td>72</td>\n",
       "      <td>1.3968</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>179</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89</td>\n",
       "      <td>156</td>\n",
       "      <td>1.6608</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>147</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76</td>\n",
       "      <td>74</td>\n",
       "      <td>1.6958</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>206</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73</td>\n",
       "      <td>127</td>\n",
       "      <td>1.4608</td>\n",
       "      <td>61</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>193</td>\n",
       "      <td>62.0</td>\n",
       "      <td>62</td>\n",
       "      <td>192</td>\n",
       "      <td>1.7798</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>120</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108</td>\n",
       "      <td>50</td>\n",
       "      <td>1.2978</td>\n",
       "      <td>54</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>139</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61</td>\n",
       "      <td>77</td>\n",
       "      <td>1.5818</td>\n",
       "      <td>68</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23</td>\n",
       "      <td>137</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70</td>\n",
       "      <td>73</td>\n",
       "      <td>1.4168</td>\n",
       "      <td>59</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36</td>\n",
       "      <td>195</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59</td>\n",
       "      <td>141</td>\n",
       "      <td>1.4498</td>\n",
       "      <td>59</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>193</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84</td>\n",
       "      <td>66</td>\n",
       "      <td>1.7938</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>47</td>\n",
       "      <td>216</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70</td>\n",
       "      <td>170</td>\n",
       "      <td>1.7238</td>\n",
       "      <td>58</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>40</td>\n",
       "      <td>200</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69</td>\n",
       "      <td>128</td>\n",
       "      <td>1.3118</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21</td>\n",
       "      <td>154</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88</td>\n",
       "      <td>121</td>\n",
       "      <td>1.2498</td>\n",
       "      <td>68</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>52</td>\n",
       "      <td>196</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90</td>\n",
       "      <td>167</td>\n",
       "      <td>1.9238</td>\n",
       "      <td>66</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>93.0</td>\n",
       "      <td>93</td>\n",
       "      <td>157</td>\n",
       "      <td>2.0508</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>46</td>\n",
       "      <td>213</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70</td>\n",
       "      <td>133</td>\n",
       "      <td>1.4788</td>\n",
       "      <td>55</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>29</td>\n",
       "      <td>173</td>\n",
       "      <td>91.0</td>\n",
       "      <td>91</td>\n",
       "      <td>221</td>\n",
       "      <td>1.4878</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>36</td>\n",
       "      <td>202</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72</td>\n",
       "      <td>273</td>\n",
       "      <td>1.8748</td>\n",
       "      <td>72</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>27</td>\n",
       "      <td>197</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72</td>\n",
       "      <td>362</td>\n",
       "      <td>1.4298</td>\n",
       "      <td>69</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>44</td>\n",
       "      <td>184</td>\n",
       "      <td>104.0</td>\n",
       "      <td>104</td>\n",
       "      <td>141</td>\n",
       "      <td>1.3268</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  weight    bmi  blood_pressure  insulin_test  liver_stress_test  \\\n",
       "0    24     151   69.0              69            72             1.3968   \n",
       "1    27     179   89.0              89           156             1.6608   \n",
       "2    34     147   76.0              76            74             1.6958   \n",
       "3    35     206   73.0              73           127             1.4608   \n",
       "4    60     193   62.0              62           192             1.7798   \n",
       "5    45     120  108.0             108            50             1.2978   \n",
       "6    20     139   61.0              61            77             1.5818   \n",
       "7    23     137   70.0              70            73             1.4168   \n",
       "8    36     195   59.0              59           141             1.4498   \n",
       "9    19     193   84.0              84            66             1.7938   \n",
       "10   47     216   70.0              70           170             1.7238   \n",
       "11   40     200   69.0              69           128             1.3118   \n",
       "12   21     154   88.0              88           121             1.2498   \n",
       "13   52     196   90.0              90           167             1.9238   \n",
       "14   30     181   93.0              93           157             2.0508   \n",
       "15   46     213   70.0              70           133             1.4788   \n",
       "16   29     173   91.0              91           221             1.4878   \n",
       "17   36     202   72.0              72           273             1.8748   \n",
       "18   27     197   72.0              72           362             1.4298   \n",
       "19   44     184  104.0             104           141             1.3268   \n",
       "\n",
       "    cardio_stress_test  years_smoking  zeta_disease  \n",
       "0                   56              4             0  \n",
       "1                   43              6             1  \n",
       "2                   53              2             0  \n",
       "3                   61              6             1  \n",
       "4                   65              9             1  \n",
       "5                   54             12             0  \n",
       "6                   68              3             0  \n",
       "7                   59              7             0  \n",
       "8                   59              6             1  \n",
       "9                   50              3             1  \n",
       "10                  58              7             1  \n",
       "11                  60              3             1  \n",
       "12                  68              4             1  \n",
       "13                  66             10             1  \n",
       "14                  80              5             1  \n",
       "15                  55             12             1  \n",
       "16                  83              3             1  \n",
       "17                  72             13             1  \n",
       "18                  69              4             1  \n",
       "19                  60              2             1  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementing simple Neural Network- Extra Analysis- Still Hyper parameters needs to be Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "800/800 [==============================] - 0s 344us/step - loss: 0.6779 - accuracy: 0.6513\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.6634 - accuracy: 0.6513\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.6589 - accuracy: 0.6513\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 0s 112us/step - loss: 0.6534 - accuracy: 0.6513\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.6489 - accuracy: 0.6513\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.6411 - accuracy: 0.6513\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.6342 - accuracy: 0.6513\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.6236 - accuracy: 0.6513\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.6107 - accuracy: 0.6513\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.6027 - accuracy: 0.6513\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.5897 - accuracy: 0.6513\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 0s 124us/step - loss: 0.5794 - accuracy: 0.6513\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.5697 - accuracy: 0.6513\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.5624 - accuracy: 0.6513\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 0s 107us/step - loss: 0.5561 - accuracy: 0.6513\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.5506 - accuracy: 0.6513\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 0s 107us/step - loss: 0.5411 - accuracy: 0.6513\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.5382 - accuracy: 0.6513\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.5354 - accuracy: 0.7337\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.5338 - accuracy: 0.7337\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.5295 - accuracy: 0.7400\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 0s 112us/step - loss: 0.5286 - accuracy: 0.7412\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.5289 - accuracy: 0.7350\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.5231 - accuracy: 0.7412\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.5255 - accuracy: 0.7312\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.5286 - accuracy: 0.7362\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.5418 - accuracy: 0.7138\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.5328 - accuracy: 0.7275\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 0s 112us/step - loss: 0.5246 - accuracy: 0.7487\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.5153 - accuracy: 0.7400\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.5270 - accuracy: 0.7462\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.5133 - accuracy: 0.7475\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.5168 - accuracy: 0.7237\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 0s 107us/step - loss: 0.5080 - accuracy: 0.7500\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.5176 - accuracy: 0.7312\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.5144 - accuracy: 0.7337\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.5117 - accuracy: 0.7375\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.5081 - accuracy: 0.7450\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 0s 106us/step - loss: 0.5123 - accuracy: 0.7350\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 0s 122us/step - loss: 0.5105 - accuracy: 0.7437\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.5083 - accuracy: 0.7425\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.4999 - accuracy: 0.7462\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.5024 - accuracy: 0.7462\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.4972 - accuracy: 0.7412\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.4972 - accuracy: 0.7325\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.4909 - accuracy: 0.7563\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.4914 - accuracy: 0.7487\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 0s 112us/step - loss: 0.4899 - accuracy: 0.7475\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.4947 - accuracy: 0.7400\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 0s 107us/step - loss: 0.4924 - accuracy: 0.7462\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 0s 122us/step - loss: 0.4942 - accuracy: 0.7437\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 0s 126us/step - loss: 0.4966 - accuracy: 0.7412\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 0s 107us/step - loss: 0.4835 - accuracy: 0.7538\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.4911 - accuracy: 0.7412\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.4912 - accuracy: 0.7487\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.4897 - accuracy: 0.7487\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.4898 - accuracy: 0.7525\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 0s 107us/step - loss: 0.4855 - accuracy: 0.7475\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.4898 - accuracy: 0.7525\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.4828 - accuracy: 0.7563\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.4860 - accuracy: 0.7462\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.4816 - accuracy: 0.7613\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.4879 - accuracy: 0.7350\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 0s 112us/step - loss: 0.4998 - accuracy: 0.7487\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.4777 - accuracy: 0.7613\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.4866 - accuracy: 0.7487\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.4869 - accuracy: 0.7525\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.4815 - accuracy: 0.7525\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.4810 - accuracy: 0.7525\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.4809 - accuracy: 0.7550\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.4770 - accuracy: 0.7525\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.4763 - accuracy: 0.7613\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.4855 - accuracy: 0.7513\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 0s 112us/step - loss: 0.4867 - accuracy: 0.7625\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.4801 - accuracy: 0.7600\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.4806 - accuracy: 0.76130s - loss: 0.4973 - accuracy: 0.74\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.4801 - accuracy: 0.7638\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.4854 - accuracy: 0.7437\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 114us/step - loss: 0.4878 - accuracy: 0.7487\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.4764 - accuracy: 0.7538\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.4775 - accuracy: 0.7513\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 0s 112us/step - loss: 0.4790 - accuracy: 0.7475\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.4821 - accuracy: 0.7425\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.4815 - accuracy: 0.7513\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.4819 - accuracy: 0.7588\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 0s 112us/step - loss: 0.4769 - accuracy: 0.7550\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.4755 - accuracy: 0.7563\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 0s 113us/step - loss: 0.4751 - accuracy: 0.7588\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 0s 109us/step - loss: 0.4694 - accuracy: 0.7650\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 0s 112us/step - loss: 0.4850 - accuracy: 0.7475\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.4769 - accuracy: 0.7513\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.4757 - accuracy: 0.7563\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 0s 110us/step - loss: 0.4787 - accuracy: 0.7513\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.4690 - accuracy: 0.7600\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 0s 112us/step - loss: 0.4727 - accuracy: 0.7650\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.4587 - accuracy: 0.77 - 0s 115us/step - loss: 0.4729 - accuracy: 0.7613\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.4753 - accuracy: 0.7550\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 0s 108us/step - loss: 0.4754 - accuracy: 0.7600\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.4779 - accuracy: 0.7462\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 0s 116us/step - loss: 0.4843 - accuracy: 0.7513\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(activation=\"relu\", input_dim=8, units=6, kernel_initializer=\"uniform\"))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\"))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\"))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)\n",
    "\n",
    "# Part 3 - Making the predictions and evaluating the model\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5)\n",
    "df_test['zeta_disease_nw']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['zeta_disease_nw']=df_test['zeta_disease_nw'].apply(lambda x:1 if x==True else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Added Column of ANN Prediction to df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>bmi</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>insulin_test</th>\n",
       "      <th>liver_stress_test</th>\n",
       "      <th>cardio_stress_test</th>\n",
       "      <th>years_smoking</th>\n",
       "      <th>zeta_disease</th>\n",
       "      <th>zeta_disease_nw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>151</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69</td>\n",
       "      <td>72</td>\n",
       "      <td>1.3968</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>179</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89</td>\n",
       "      <td>156</td>\n",
       "      <td>1.6608</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>147</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76</td>\n",
       "      <td>74</td>\n",
       "      <td>1.6958</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>206</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73</td>\n",
       "      <td>127</td>\n",
       "      <td>1.4608</td>\n",
       "      <td>61</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>193</td>\n",
       "      <td>62.0</td>\n",
       "      <td>62</td>\n",
       "      <td>192</td>\n",
       "      <td>1.7798</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>120</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108</td>\n",
       "      <td>50</td>\n",
       "      <td>1.2978</td>\n",
       "      <td>54</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>139</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61</td>\n",
       "      <td>77</td>\n",
       "      <td>1.5818</td>\n",
       "      <td>68</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23</td>\n",
       "      <td>137</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70</td>\n",
       "      <td>73</td>\n",
       "      <td>1.4168</td>\n",
       "      <td>59</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36</td>\n",
       "      <td>195</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59</td>\n",
       "      <td>141</td>\n",
       "      <td>1.4498</td>\n",
       "      <td>59</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>193</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84</td>\n",
       "      <td>66</td>\n",
       "      <td>1.7938</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>47</td>\n",
       "      <td>216</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70</td>\n",
       "      <td>170</td>\n",
       "      <td>1.7238</td>\n",
       "      <td>58</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>40</td>\n",
       "      <td>200</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69</td>\n",
       "      <td>128</td>\n",
       "      <td>1.3118</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21</td>\n",
       "      <td>154</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88</td>\n",
       "      <td>121</td>\n",
       "      <td>1.2498</td>\n",
       "      <td>68</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>52</td>\n",
       "      <td>196</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90</td>\n",
       "      <td>167</td>\n",
       "      <td>1.9238</td>\n",
       "      <td>66</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>30</td>\n",
       "      <td>181</td>\n",
       "      <td>93.0</td>\n",
       "      <td>93</td>\n",
       "      <td>157</td>\n",
       "      <td>2.0508</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>46</td>\n",
       "      <td>213</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70</td>\n",
       "      <td>133</td>\n",
       "      <td>1.4788</td>\n",
       "      <td>55</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>29</td>\n",
       "      <td>173</td>\n",
       "      <td>91.0</td>\n",
       "      <td>91</td>\n",
       "      <td>221</td>\n",
       "      <td>1.4878</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>36</td>\n",
       "      <td>202</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72</td>\n",
       "      <td>273</td>\n",
       "      <td>1.8748</td>\n",
       "      <td>72</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>27</td>\n",
       "      <td>197</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72</td>\n",
       "      <td>362</td>\n",
       "      <td>1.4298</td>\n",
       "      <td>69</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>44</td>\n",
       "      <td>184</td>\n",
       "      <td>104.0</td>\n",
       "      <td>104</td>\n",
       "      <td>141</td>\n",
       "      <td>1.3268</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  weight    bmi  blood_pressure  insulin_test  liver_stress_test  \\\n",
       "0    24     151   69.0              69            72             1.3968   \n",
       "1    27     179   89.0              89           156             1.6608   \n",
       "2    34     147   76.0              76            74             1.6958   \n",
       "3    35     206   73.0              73           127             1.4608   \n",
       "4    60     193   62.0              62           192             1.7798   \n",
       "5    45     120  108.0             108            50             1.2978   \n",
       "6    20     139   61.0              61            77             1.5818   \n",
       "7    23     137   70.0              70            73             1.4168   \n",
       "8    36     195   59.0              59           141             1.4498   \n",
       "9    19     193   84.0              84            66             1.7938   \n",
       "10   47     216   70.0              70           170             1.7238   \n",
       "11   40     200   69.0              69           128             1.3118   \n",
       "12   21     154   88.0              88           121             1.2498   \n",
       "13   52     196   90.0              90           167             1.9238   \n",
       "14   30     181   93.0              93           157             2.0508   \n",
       "15   46     213   70.0              70           133             1.4788   \n",
       "16   29     173   91.0              91           221             1.4878   \n",
       "17   36     202   72.0              72           273             1.8748   \n",
       "18   27     197   72.0              72           362             1.4298   \n",
       "19   44     184  104.0             104           141             1.3268   \n",
       "\n",
       "    cardio_stress_test  years_smoking  zeta_disease  zeta_disease_nw  \n",
       "0                   56              4             0                0  \n",
       "1                   43              6             1                0  \n",
       "2                   53              2             0                0  \n",
       "3                   61              6             1                0  \n",
       "4                   65              9             1                1  \n",
       "5                   54             12             0                0  \n",
       "6                   68              3             0                0  \n",
       "7                   59              7             0                0  \n",
       "8                   59              6             1                1  \n",
       "9                   50              3             1                0  \n",
       "10                  58              7             1                1  \n",
       "11                  60              3             1                0  \n",
       "12                  68              4             1                0  \n",
       "13                  66             10             1                0  \n",
       "14                  80              5             1                0  \n",
       "15                  55             12             1                1  \n",
       "16                  83              3             1                0  \n",
       "17                  72             13             1                1  \n",
       "18                  69              4             1                0  \n",
       "19                  60              2             1                0  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observation: Since we need to tuned parameters in ANN it didnt perform very well. Needs to work on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
